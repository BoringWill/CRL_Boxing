import torch
import numpy as np
import cv2
import pygame
import time
import os
from collections import deque
from pettingzoo.atari import pong_v3

from model import PongAgent
from config import Config

# ================= é…ç½®åŒº =================
P1_MODE = "AI"  # "AI" æˆ– "HUMAN"
P2_MODE = "AI"  # "AI" æˆ– "HUMAN"

P1_MODEL_PATH = "pong_models/20260208_160029/latest_student.pth"
P2_MODEL_PATH = "pong_models/20260208_160029/examiner_model.pth"

# å­—ç¬¦ç”»é…ç½®
ASCII_WIDTH = 60   # å»ºè®®æ ¹æ®ç»ˆç«¯å¤§å°è°ƒæ•´
ASCII_HEIGHT = 20
# ==========================================

class TestEnv:
    """ä¸“ç”¨äºæµ‹è¯•çš„ç®€å•åŒ…è£…å™¨ï¼Œæ”¯æŒæ¸²æŸ“å’Œå¸§å †å """
    def __init__(self):
        self.env = pong_v3.parallel_env(
            render_mode=None, # ä¿®æ”¹ç‚¹ï¼šå…³é—­ GUI æ¸²æŸ“ï¼Œå› ä¸ºæˆ‘ä»¬è¦çœ‹ ASCII
            full_action_space=False,
            obs_type="grayscale_image"
        )
        self.frames_p1 = deque(maxlen=4)
        self.frames_p2 = deque(maxlen=4)

    def reset(self):
        obs, _ = self.env.reset()
        # ä¿å­˜åŸå§‹ç°åº¦å›¾ç”¨äº ASCII æ¸²æŸ“
        self.last_raw_obs = obs["first_0"]
        p1_img = cv2.resize(obs["first_0"], (84, 84))
        p2_img = cv2.resize(obs["second_0"], (84, 84))
        for _ in range(4):
            self.frames_p1.append(p1_img)
            self.frames_p2.append(p2_img)
        return self._get_obs()

    def _get_obs(self):
        return np.stack(self.frames_p1, axis=-1), np.stack(self.frames_p2, axis=-1)

    def step(self, actions):
        obs, rewards, terms, truncs, infos = self.env.step(actions)
        self.last_raw_obs = obs["first_0"]
        p1_img = cv2.resize(obs["first_0"], (84, 84))
        p2_img = cv2.resize(obs["second_0"], (84, 84))
        self.frames_p1.append(p1_img)
        self.frames_p2.append(p2_img)
        done = any(terms.values()) or any(truncs.values())
        return self._get_obs(), rewards, done

def render_ascii(obs):
    """æ¸²æŸ“å‡½æ•°ï¼šå°†ç°åº¦å›¾è½¬ä¸ºå­—ç¬¦ç”»"""
    small_img = cv2.resize(obs, (ASCII_WIDTH, ASCII_HEIGHT))
    chars = [" ", ".", ":", "-", "=", "+", "*", "#", "%", "@"]
    output = "\033[H"  # ANSI é€ƒé€¸ç ï¼šå°†å…‰æ ‡é‡ç½®åˆ°å·¦ä¸Šè§’
    output += "+" + "-" * ASCII_WIDTH + "+\n"
    for row in small_img:
        line = "|"
        for pixel in row:
            line += chars[min(pixel // 26, 9)]
        output += line + "|\n"
    output += "+" + "-" * ASCII_WIDTH + "+"
    print(output)

def get_human_actions():
    pygame.event.pump()
    keys = pygame.key.get_pressed()
    p1, p2 = 0, 0
    if keys[pygame.K_w]: p1 = 2
    elif keys[pygame.K_s]: p1 = 3
    if keys[pygame.K_UP]: p2 = 2
    elif keys[pygame.K_DOWN]: p2 = 3
    return p1, p2

def load_model(path, device):
    agent = PongAgent().to(device)
    if not os.path.exists(path):
        print(f"âš ï¸ è­¦å‘Š: æ¨¡å‹æ–‡ä»¶ä¸å­˜åœ¨ {path}")
        return agent
    state_dict = torch.load(path, map_location=device)
    agent.load_state_dict(state_dict["model_state_dict"] if "model_state_dict" in state_dict else state_dict)
    agent.eval()
    return agent

def run():
    # è™½ç„¶ä¸æ˜¾ç¤ºçª—å£ï¼Œä½†ä¸ºäº†ç›‘å¬é”®ç›˜(HUMANæ¨¡å¼)ï¼Œä»éœ€åˆå§‹åŒ– pygame
    pygame.init()
    # åˆ›å»ºä¸€ä¸ªéšè—çš„ surface ç”¨æ¥å¤„ç†äº‹ä»¶
    if P1_MODE == "HUMAN" or P2_MODE == "HUMAN":
        pygame.display.set_mode((1, 1), pygame.NOFRAME)

    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    env = TestEnv()

    p1_ai = load_model(P1_MODEL_PATH, device) if P1_MODE == "AI" else None
    p2_ai = load_model(P2_MODEL_PATH, device) if P2_MODE == "AI" else None

    # æ¸…å±
    os.system('cls' if os.name == 'nt' else 'clear')
    print(f"ğŸš€ ASCII æ¨¡å¼å¯¹æˆ˜: P1:{P1_MODE} vs P2:{P2_MODE}")

    obs_p1, obs_p2 = env.reset()

    try:
        while True:
            # ä½ çš„åŸæœ‰é€»è¾‘å®Œå…¨ä¿ç•™
            actions = {}
            h_p1, h_p2 = get_human_actions()

            if P1_MODE == "AI":
                with torch.no_grad():
                    t = torch.as_tensor(obs_p1, dtype=torch.float32).unsqueeze(0).to(device)
                    actions["first_0"] = p1_ai.get_action_and_value(t)[0].item()
            else:
                actions["first_0"] = h_p1

            if P2_MODE == "AI":
                with torch.no_grad():
                    t = torch.as_tensor(obs_p2, dtype=torch.float32).unsqueeze(0).to(device)
                    actions["second_0"] = p2_ai.get_action_and_value(t)[0].item()
            else:
                actions["second_0"] = h_p2

            (obs_p1, obs_p2), rewards, done = env.step(actions)

            # --- å˜ç›¸è§‚å¯Ÿï¼šæ¸²æŸ“å­—ç¬¦ç”» ---
            render_ascii(env.last_raw_obs)
            # é¡ºä¾¿è¾“å‡ºå½“å‰åŠ¨ä½œï¼Œæ–¹ä¾¿è°ƒè¯•
            print(f"åŠ¨ä½œ | P1: {actions['first_0']}  P2: {actions['second_0']} | å¥–åŠ±: {rewards}          ", end="")

            time.sleep(1 / 45) # ç¨å¾®åŠ å¿«ä¸€ç‚¹ç‚¹ï¼Œç»ˆç«¯æ¸²æŸ“æœ‰å»¶è¿Ÿ

            if done:
                obs_p1, obs_p2 = env.reset()

    except KeyboardInterrupt:
        print("\nâ¹ åœæ­¢æµ‹è¯•")
    finally:
        pygame.quit()

if __name__ == "__main__":
    run()